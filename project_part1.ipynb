{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project Part 1\n",
    "\n",
    "A) An introductory proposal section describing what it is your doing to do and where the dataset originates\n",
    "B) An exploratory analysis section that has the histograms, charts, tables, etc. that are the output from your exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Introduction/Background\n",
    "\n",
    "In this notebook, I am using two distinct datasets, one which provides twenty-thousand English language statements,\n",
    "as well as the AFINN Lexicon Dataset which assigns a value between -5 (Most negative connotation) and +5 (Most positive connotation)\n",
    "to 2,477 English language words. The AFINN dataset is static. I seek to enhance the accuracy of the Statements dataset by first calculating\n",
    "the sum of AFINN values for each statement. This will be followed by Deep Learning in the coming parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "* https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools\n",
    "* https://regenerativetoday.com/exploratory-data-analysis-of-text-data-including-visualization-and-sentiment-analysis/\n",
    "* https://medium.com/swlh/text-summarization-guide-exploratory-data-analysis-on-text-data-4e22ce2dd6ad  \n",
    "* https://www.kdnuggets.com/2019/05/complete-exploratory-data-analysis-visualization-text-data.html  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib, numpy, nltk\n",
    "import sklearn, gensim, wordcloud\n",
    "import textblob, spacy, textstat\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, tqdm_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cjens\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = pd.read_csv(\"dataset/Statements/Data-all.csv\")\n",
    "lexiconAFINN = pd.read_csv(\"dataset/Lexicons/afinn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           Statement  Emotion\n0  a boyfriend with whom i split up with came ove...    anger\n1  a certain friend tried to push me off a seat i...    anger\n2         a father of children killed in an accident  sadness\n3                                   a few monthe ago    anger\n4  a friend of mine suggested that i become a fil...      joy",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Statement</th>\n      <th>Emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a boyfriend with whom i split up with came ove...</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a certain friend tried to push me off a seat i...</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a father of children killed in an accident</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a few monthe ago</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a friend of mine suggested that i become a fil...</td>\n      <td>joy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statements.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0       word  value\n0           1    abandon     -2\n1           2  abandoned     -2\n2           3   abandons     -2\n3           4   abducted     -2\n4           5  abduction     -2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>word</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>abandon</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>abandoned</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>abandons</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>abducted</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>abduction</td>\n      <td>-2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexiconAFINN.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'a'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9136\\166737203.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mafinnDict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlexiconAFINN\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlexiconAFINN\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mstmtAfinnValues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstatements\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mStatement\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mstmt\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mafinnDict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mw\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mstmt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4431\u001B[0m         \u001B[0mdtype\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mfloat64\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4432\u001B[0m         \"\"\"\n\u001B[1;32m-> 4433\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mSeriesApply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconvert_dtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4434\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4435\u001B[0m     def _reduce(\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1086\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1087\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1088\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1089\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1090\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0magg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1141\u001B[0m                 \u001B[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1142\u001B[0m                 \u001B[1;31m# \"Callable[[Any], Any]\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1143\u001B[1;33m                 mapped = lib.map_infer(\n\u001B[0m\u001B[0;32m   1144\u001B[0m                     \u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1145\u001B[0m                     \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;31m# type: ignore[arg-type]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9136\\166737203.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(stmt)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mafinnDict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlexiconAFINN\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlexiconAFINN\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mstmtAfinnValues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstatements\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mStatement\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mstmt\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mafinnDict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mw\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mstmt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9136\\166737203.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mafinnDict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlexiconAFINN\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlexiconAFINN\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mstmtAfinnValues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstatements\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mStatement\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mstmt\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mafinnDict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mw\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mstmt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'a'"
     ]
    }
   ],
   "source": [
    "afinnDict = dict(zip(lexiconAFINN.word, lexiconAFINN.value))\n",
    "stmtAfinnValues = pd.Series(statements.Statement.apply(lambda stmt: sum([afinnDict[w] for w in stmt.split()]), 1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
