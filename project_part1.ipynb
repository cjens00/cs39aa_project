{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project Part 1\n",
    "\n",
    "A) An introductory proposal section describing what it is your doing to do and where the dataset originates\n",
    "B) An exploratory analysis section that has the histograms, charts, tables, etc. that are the output from your exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Introduction/Background\n",
    "\n",
    "In this notebook, I am using two distinct datasets, one which provides twenty-thousand English language statements,\n",
    "as well as the AFINN Lexicon Dataset which assigns a value between -5 (Most negative connotation) and +5 (Most positive connotation)\n",
    "to 2,477 English language words. The AFINN dataset is static. I seek to enhance the accuracy of the Statements dataset by first calculating\n",
    "the sum of AFINN values for each statement. This will be followed by Deep Learning in the coming parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "* https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools\n",
    "* https://regenerativetoday.com/exploratory-data-analysis-of-text-data-including-visualization-and-sentiment-analysis/\n",
    "* https://medium.com/swlh/text-summarization-guide-exploratory-data-analysis-on-text-data-4e22ce2dd6ad  \n",
    "* https://www.kdnuggets.com/2019/05/complete-exploratory-data-analysis-visualization-text-data.html  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib, numpy, nltk\n",
    "import sklearn, gensim, wordcloud\n",
    "import textblob, spacy, textstat\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, tqdm_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cjens\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = pd.read_csv(\"dataset/Statements/Data-all.csv\")\n",
    "lexiconAFINN = pd.read_csv(\"dataset/Lexicons/afinn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           Statement  Emotion\n0  a boyfriend with whom i split up with came ove...    anger\n1  a certain friend tried to push me off a seat i...    anger\n2         a father of children killed in an accident  sadness\n3                                   a few monthe ago    anger\n4  a friend of mine suggested that i become a fil...      joy",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Statement</th>\n      <th>Emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a boyfriend with whom i split up with came ove...</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a certain friend tried to push me off a seat i...</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a father of children killed in an accident</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a few monthe ago</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a friend of mine suggested that i become a fil...</td>\n      <td>joy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statements.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0       word  value\n0           1    abandon     -2\n1           2  abandoned     -2\n2           3   abandons     -2\n3           4   abducted     -2\n4           5  abduction     -2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>word</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>abandon</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>abandoned</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>abandons</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>abducted</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>abduction</td>\n      <td>-2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexiconAFINN.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "afinnDict = dict(zip(lexiconAFINN.word, lexiconAFINN.value))\n",
    "stmtAfinnValues = pd.Series(statements.Statement.apply(lambda stmt: sum([afinnDict[w] for w in stmt.split() if w in afinnDict]), 1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "0        1\n1        0\n2       -5\n3        0\n4        4\n        ..\n19995    0\n19996    0\n19997    3\n19998    0\n19999    4\nName: Statement, Length: 20000, dtype: int64"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stmtAfinnValues"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
